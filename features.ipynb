{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting words into subwords using GPT-small\n",
    "\n",
    "def tokenize_words_into_subwords(words):\n",
    "  subword_list = []\n",
    "  makeup_word_list = []\n",
    "  for word in words:\n",
    "    if word in words_to_ignore:\n",
    "      subword_list.append(word)\n",
    "      makeup_word_list.append(word)\n",
    "    else:\n",
    "      tokens = tokenizer.tokenize(word)\n",
    "      makeup_word = tokenizer.convert_tokens_to_string(tokens)\n",
    "      #print(makeup_word)\n",
    "      subword_list.append(tokens)\n",
    "      makeup_word_list.append(makeup_word)\n",
    "  return subword_list, makeup_word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of sub-words  and the length of each sub-word\n",
    "\n",
    "def calculate_subword_info(subwords):\n",
    "  num_subwords = []\n",
    "  subword_lengths = []\n",
    "  subword_infos = []            # subword position within a subword ('un', 'believable') --> (1-1, 1-2)\n",
    "  for sw in subwords:\n",
    "    if sw in words_to_ignore:\n",
    "      num_subwords.append(-99)\n",
    "      subword_lengths.append(-99)\n",
    "    else:\n",
    "      num_subwords.append(len(sw))\n",
    "      subword_length = [len(sub) for sub in sw]\n",
    "      subword_lengths.append(subword_length)\n",
    "    #print(swlen)\n",
    "\n",
    "  for i, sw in enumerate(subwords, 1):           # Enumerate over subwords\n",
    "    if sw in words_to_ignore:\n",
    "      subword_infos.append(-99)\n",
    "    else:\n",
    "      subword_info = [f\"{wnum[i]}-{j}\" for j in range(1, len(sw) + 1)]  # Creating subword info for each subword\n",
    "      subword_infos.append(subword_info)\n",
    "\n",
    "  return num_subwords, subword_lengths, subword_infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Gaze landed within the fixated sub-word\n",
    "\n",
    "def gaze_landed_on_subwords(cleaned_subwords, wdlp):\n",
    "  char_fixated = []\n",
    "  which_subpart = []\n",
    "  within_subword = []\n",
    "\n",
    "  for k, subword in enumerate(cleaned_subwords, 1):\n",
    "    cumulative_length = 0\n",
    "    zero_appended = False\n",
    "\n",
    "    # Handling the case when subword is in words_to_ignore and wdlp is -99\n",
    "    if subword in words_to_ignore and int(wdlp[k-1]) == -99:\n",
    "      char_fixated.append(-99)\n",
    "      which_subpart.append(-99)\n",
    "      within_subword.append(-99)\n",
    "    else:\n",
    "      subword_char_fixated = []\n",
    "      subword_which_subpart = []\n",
    "      subword_within_subword = []\n",
    "\n",
    "      for i, j in enumerate(subword, 1):\n",
    "        offset = cumulative_length\n",
    "        cumulative_length += len(j)\n",
    "\n",
    "        if int(wdlp[k-1]) == 0 :              #and not zero_appended\n",
    "          subword_char_fixated.append(0)\n",
    "          subword_which_subpart.append(0)\n",
    "          subword_within_subword.append(0)\n",
    "          #zero_appended = True\n",
    "        else:\n",
    "          if int(wdlp[k-1]) <= cumulative_length:\n",
    "            wdlp_value = int(wdlp[k-1]) - offset\n",
    "            #print(\"wdlp_value:\", wdlp_value)\n",
    "            #print(\"j:\", j)\n",
    "            if wdlp_value <= len(j):          # and wdlp_value > 0\n",
    "              sw = j[wdlp_value - 1 ]\n",
    "              subword_char_fixated.append(sw)\n",
    "              subword_which_subpart.append(j)\n",
    "              subword_within_subword.append(wdlp_value)\n",
    "              break\n",
    "            else:\n",
    "              print(\"Error: WDLP exceeds subword boundaries.\")\n",
    "\n",
    "      char_fixated.append(subword_char_fixated)\n",
    "      which_subpart.append(subword_which_subpart)\n",
    "      within_subword.append(subword_within_subword)\n",
    "\n",
    "\n",
    "  return char_fixated, which_subpart, within_subword\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
